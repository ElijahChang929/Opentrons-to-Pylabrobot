{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a744ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    " ------------- Operating the heater shaker------------\n",
    "\n",
    "Setting Target Temperature of Heater-Shaker to 37 °C\n",
    "Waiting for Heater-Shaker to reach target temperature\n",
    "Setting Heater-Shaker to Shake at 200 RPM and waiting until reached\n",
    "Delaying for 60 minutes and 0.0 seconds\n",
    "Deactivating Heater\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef093349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "MODULE_START_PATTERNS = [\n",
    "    r\"Setting Target Temperature of Heater-Shaker\"   # only split on heater‑shaker for now\n",
    "]\n",
    "\n",
    "# Input: Multiline protocol text\n",
    "# with open(\"/mnt/data/opentrons_protocol.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "#     lines = file.readlines()\n",
    "text_ = text.replace(\"\\n        \", \";\")\n",
    "lines = text_.strip().split('\\n')\n",
    "\n",
    "# Strip lines, ignore indented lines (children/substeps), and filter empty lines\n",
    "steps = [line.replace(\";\", \"\\n        \").strip() for line in lines if line.strip() and not line.startswith(\"        \") and not line.startswith(\"~~\") and not \"--\" in line and not line.endswith(\":\")]\n",
    "\n",
    "# Define prepositions to split on\n",
    "PREPOSITIONS = [' from ', ' to ', ' on ', ' of ', ' into ']\n",
    "\n",
    "# Structure for collecting parsed results\n",
    "parsed_steps = []\n",
    "\n",
    "# Parse each line\n",
    "for line in steps:\n",
    "    tokens = [line]\n",
    "    for prep in PREPOSITIONS:\n",
    "        new_tokens = []\n",
    "        for token in tokens:\n",
    "            new_tokens.extend(token.split(prep))\n",
    "        tokens = new_tokens\n",
    "    parsed_steps.append({\n",
    "        \"raw\": line,\n",
    "        \"tokens\": [t.strip() for t in tokens if t.strip()]\n",
    "    })\n",
    "\n",
    "# Group steps into phases based on \"Aspirating\"\n",
    "grouped_phases = []\n",
    "current_phase = []\n",
    "aspirating_seen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last = \"\"\n",
    "for step in parsed_steps:\n",
    "    if (step[\"raw\"].startswith(\"Aspirating\") and not (\"Picking up tip\" in last) and not (\"Moving to\" in last) and not (\"Transferring\" in last)) \\\n",
    "        or (\"Picking up tip\" in step[\"raw\"]) or (\"Moving to\" in step[\"raw\"] and not (\"Picking up tip\" in last)):\n",
    "        if aspirating_seen:\n",
    "            grouped_phases.append(current_phase)\n",
    "            current_phase = []\n",
    "        aspirating_seen = True\n",
    "    last = step[\"raw\"]\n",
    "    current_phase.append(step[\"raw\"])\n",
    "\n",
    "# Append the last batch\n",
    "if current_phase:\n",
    "    grouped_phases.append(current_phase)\n",
    "\n",
    "# Output the grouped phases\n",
    "import pandas as pd\n",
    "\n",
    "grouped_dict = {\"Phase {}\".format(i + 1): phase for i, phase in enumerate(grouped_phases)}\n",
    "df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in grouped_dict.items() ]))\n",
    "\n",
    "# Also, extract all distinct actions (first word in each step)\n",
    "actions = set()\n",
    "for step in parsed_steps:\n",
    "    action = step[\"raw\"].split()[0]\n",
    "    actions.add(action)\n",
    "\n",
    "sorted_actions = sorted(actions)\n",
    "sorted_actions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylabrobot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
